
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../images/favicon.ico">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.2.11">
    
    
      
        <title>Case Studies - MITRE | ATLAS</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c5ef100.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.9647289d.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#case-studies" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="MITRE | ATLAS" class="md-header__button md-logo" aria-label="MITRE | ATLAS" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 11c0 5.55-3.84 10.74-9 12-5.16-1.26-9-6.45-9-12V5l9-4 9 4v6m-9 10c3.75-1 7-5.46 7-9.78V6.3l-7-3.12V21Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MITRE | ATLAS
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Case Studies
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_3" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_3">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href=".." class="md-tabs__link">
      Overview
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../faq/" class="md-tabs__link">
      FAQ
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="./" class="md-tabs__link md-tabs__link--active">
        Case studies
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../tactics/" class="md-tabs__link">
        Tactics
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../techniques/" class="md-tabs__link">
        Techniques
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="MITRE | ATLAS" class="md-nav__button md-logo" aria-label="MITRE | ATLAS" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 11c0 5.55-3.84 10.74-9 12-5.16-1.26-9-6.45-9-12V5l9-4 9 4v6m-9 10c3.75-1 7-5.46 7-9.78V6.3l-7-3.12V21Z"/></svg>

    </a>
    MITRE | ATLAS
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index md-nav__link--active">
          <a href="./">Case studies</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Case studies" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Case studies
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0000/" class="md-nav__link">
        Evasion of Deep Learning Detector for Malware C&C Traffic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0001/" class="md-nav__link">
        Botnet Domain Generation Algorithm (DGA) Detection Evasion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0002/" class="md-nav__link">
        VirusTotal Poisoning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0003/" class="md-nav__link">
        Bypassing Cylance's AI Malware Detection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0004/" class="md-nav__link">
        Camera Hijack Attack on Facial Recognition System
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0005/" class="md-nav__link">
        Attack on Machine Translation Service - Google Translate, Bing Translator, and Systran Translate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0006/" class="md-nav__link">
        ClearviewAI Misconfiguration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0007/" class="md-nav__link">
        GPT-2 Model Replication
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0008/" class="md-nav__link">
        ProofPoint Evasion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0009/" class="md-nav__link">
        Tay Poisoning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0010/" class="md-nav__link">
        Microsoft Azure Service Disruption
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0011/" class="md-nav__link">
        Microsoft Edge AI Evasion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0012/" class="md-nav__link">
        Face Identification System Evasion via Physical Countermeasures
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0013/" class="md-nav__link">
        Backdoor Attack on Deep Learning Models in Mobile Apps
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="AML.CS0014/" class="md-nav__link">
        Confusing Antimalware Neural Networks
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../tactics/">Tactics</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Tactics" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Tactics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0000/" class="md-nav__link">
        ML Model Access
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0001/" class="md-nav__link">
        ML Attack Staging
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0002/" class="md-nav__link">
        Reconnaissance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0003/" class="md-nav__link">
        Resource Development
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0004/" class="md-nav__link">
        Initial Access
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0005/" class="md-nav__link">
        Execution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0006/" class="md-nav__link">
        Persistence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0007/" class="md-nav__link">
        Defense Evasion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0008/" class="md-nav__link">
        Discovery
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0009/" class="md-nav__link">
        Collection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0010/" class="md-nav__link">
        Exfiltration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tactics/AML.TA0011/" class="md-nav__link">
        Impact
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../techniques/">Techniques</a>
          
            <label for="__nav_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Techniques" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Techniques
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0000.000/" class="md-nav__link">
        Search for Victim's Publicly Available Research Materials: Journals and Conference Proceedings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0000.001/" class="md-nav__link">
        Search for Victim's Publicly Available Research Materials: Pre-Print Repositories
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0000.002/" class="md-nav__link">
        Search for Victim's Publicly Available Research Materials: Technical Blogs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0000/" class="md-nav__link">
        Search for Victim's Publicly Available Research Materials
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0001/" class="md-nav__link">
        Search for Publicly Available Adversarial Vulnerability Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0002.000/" class="md-nav__link">
        Acquire Public ML Artifacts: Datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0002.001/" class="md-nav__link">
        Acquire Public ML Artifacts: Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0002/" class="md-nav__link">
        Acquire Public ML Artifacts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0003/" class="md-nav__link">
        Search Victim-Owned Websites
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0004/" class="md-nav__link">
        Search Application Repositories
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0005.000/" class="md-nav__link">
        Create Proxy ML Model: Train Proxy via Gathered ML Artifacts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0005.001/" class="md-nav__link">
        Create Proxy ML Model: Train Proxy via Replication
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0005.002/" class="md-nav__link">
        Create Proxy ML Model: Use Pre-Trained Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0005/" class="md-nav__link">
        Create Proxy ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0006/" class="md-nav__link">
        Active Scanning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0007/" class="md-nav__link">
        Discover ML Artifacts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0008.000/" class="md-nav__link">
        Acquire Infrastructure: ML Development Workspaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0008.001/" class="md-nav__link">
        Acquire Infrastructure: Consumer Hardware
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0008/" class="md-nav__link">
        Acquire Infrastructure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0010.000/" class="md-nav__link">
        ML Supply Chain Compromise: GPU Hardware
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0010.001/" class="md-nav__link">
        ML Supply Chain Compromise: ML Software
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0010.002/" class="md-nav__link">
        ML Supply Chain Compromise: Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0010.003/" class="md-nav__link">
        ML Supply Chain Compromise: Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0010/" class="md-nav__link">
        ML Supply Chain Compromise
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0011.000/" class="md-nav__link">
        User Execution: Unsafe ML Artifacts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0011/" class="md-nav__link">
        User Execution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0012/" class="md-nav__link">
        Valid Accounts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0013/" class="md-nav__link">
        Discover ML Model Ontology
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0014/" class="md-nav__link">
        Discover ML Model Family
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0015/" class="md-nav__link">
        Evade ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0016.000/" class="md-nav__link">
        Obtain Capabilities: Adversarial ML Attack Implementations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0016.001/" class="md-nav__link">
        Obtain Capabilities: Software Tools
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0016/" class="md-nav__link">
        Obtain Capabilities
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0017/" class="md-nav__link">
        Develop Adversarial ML Attack Capabilities
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0018.000/" class="md-nav__link">
        Backdoor ML Model: Poison ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0018.001/" class="md-nav__link">
        Backdoor ML Model: Inject Payload
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0018/" class="md-nav__link">
        Backdoor ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0019/" class="md-nav__link">
        Publish Poisoned Datasets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0020/" class="md-nav__link">
        Poison Training Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0021/" class="md-nav__link">
        Establish Accounts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0024.000/" class="md-nav__link">
        Exfiltration via ML Inference API: Infer Training Data Membership
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0024.001/" class="md-nav__link">
        Exfiltration via ML Inference API: Invert ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0024.002/" class="md-nav__link">
        Exfiltration via ML Inference API: Extract ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0024/" class="md-nav__link">
        Exfiltration via ML Inference API
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0025/" class="md-nav__link">
        Exfiltration via Cyber Means
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0029/" class="md-nav__link">
        Denial of ML Service
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0031/" class="md-nav__link">
        Erode ML Model Integrity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0034/" class="md-nav__link">
        Cost Harvesting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0035/" class="md-nav__link">
        ML Artifact Collection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0036/" class="md-nav__link">
        Data from Information Repositories
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0040/" class="md-nav__link">
        ML Model Inference API Access
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0041/" class="md-nav__link">
        Physical Environment Access
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0042/" class="md-nav__link">
        Verify Attack
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0043.000/" class="md-nav__link">
        Craft Adversarial Data: White-Box Optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0043.001/" class="md-nav__link">
        Craft Adversarial Data: Black-Box Optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0043.002/" class="md-nav__link">
        Craft Adversarial Data: Black-Box Transfer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0043.003/" class="md-nav__link">
        Craft Adversarial Data: Manual Modification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0043.004/" class="md-nav__link">
        Craft Adversarial Data: Insert Backdoor Trigger
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0043/" class="md-nav__link">
        Craft Adversarial Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0044/" class="md-nav__link">
        Full ML Model Access
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0045/" class="md-nav__link">
        ML Intellectual Property Theft
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0046/" class="md-nav__link">
        Spamming ML System with Chaff Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../techniques/AML.T0047/" class="md-nav__link">
        ML-Enabled Product or Service
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="case-studies">Case Studies</h1>
<p>Attacks on machine learning (ML) systems are being developed and released with increased regularity. Attacks have historically been performed in controlled settings, but attacks are increasingly observed on production systems. Deployed ML systems can have many vulnerabilities, for example trained on personally identifiable information, trusted to make critical decisions with little oversight, and have little to no logging and alerting attached to their use.</p>
<p>MITRE ATLAS™ case studies are selected because of the impact to production ML systems. Each demonstrates one of the following characteristics:</p>
<ol>
<li>
<p>Range of Attacks: Evasion, poisoning, model replication and exploiting traditional software flaws.</p>
</li>
<li>
<p>Range of Personas: Average user, security researchers, ML researchers and fully-equipped Red team.</p>
</li>
<li>
<p>Range of ML Paradigms: Attacks on MLaaS, ML models hosted on cloud, hosted on-premise, ML models on edge.</p>
</li>
<li>
<p>Range of Use Case: Attacks on ML systems used in both "security-sensitive" applications like cybersecurity and non-security-sensitive applications like chatbots.</p>
</li>
</ol>
<p>The table below lists case-studies from MITRE ATLAS™. Scroll through the table or use the sidebar to access more information.</p>
<table>
<thead>
<tr>
<th align="left">ID</th>
<th align="left">Name</th>
<th align="left">Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><a href="AML.CS0000">AML.CS0000</a></td>
<td align="left"><a href="AML.CS0000">Evasion of Deep Learning Detector for Malware C&amp;C Traffic</a></td>
<td align="left">The Palo Alto Networks Security AI research team tested a deep learning model for malware command and control (C&amp;C) traffic detection in HTTP traffic. Based on the publicly available <a href="https://arxiv.org/abs/1802.03162">paper by Le et al.</a>, we built a model that was trained on a similar dataset as our production model and had similar performance. Then we crafted adversarial samples, queried the model, and adjusted the adversarial sample accordingly until the model was evaded.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0001">AML.CS0001</a></td>
<td align="left"><a href="AML.CS0001">Botnet Domain Generation Algorithm (DGA) Detection Evasion</a></td>
<td align="left">The Palo Alto Networks Security AI research team was able to bypass a Convolutional Neural Network based botnet Domain Generation Algorithm (DGA) detector using a generic domain name mutation technique. It is a generic domain mutation technique which can evade most ML-based DGA detection modules. The generic mutation technique evades most ML-based DGA detection modules DGA and can be used to test the effectiveness and robustness of all DGA detection methods developed by security companies in the industry before they is deployed to the production environment.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0002">AML.CS0002</a></td>
<td align="left"><a href="AML.CS0002">VirusTotal Poisoning</a></td>
<td align="left">McAfee Advanced Threat Research noticed an increase in reports of a certain ransomware family that was out of the ordinary. Case investigation revealed that many samples of that particular ransomware family were submitted through a popular virus-sharing platform within a short amount of time. Further investigation revealed that based on string similarity the samples were all equivalent, and based on code similarity they were between 98 and 74 percent similar. Interestingly enough, the compile time was the same for all the samples. After more digging, researchers discovered that someone used 'metame' a metamorphic code manipulating tool to manipulate the original file towards mutant variants. The variants would not always be executable, but are still classified as the same ransomware family.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0003">AML.CS0003</a></td>
<td align="left"><a href="AML.CS0003">Bypassing Cylance's AI Malware Detection</a></td>
<td align="left">Researchers at Skylight were able to create a universal bypass string that evades detection by Cylance's AI Malware detector when appended to a malicious file.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0004">AML.CS0004</a></td>
<td align="left"><a href="AML.CS0004">Camera Hijack Attack on Facial Recognition System</a></td>
<td align="left">This type of camera hijack attack can evade the traditional live facial recognition authentication model and enable access to privileged systems and victim impersonation.  Two individuals in China used this attack to gain access to the local government's tax system. They created a fake shell company and sent invoices via tax system to supposed clients. The individuals started this scheme in 2018 and were able to fraudulently collect $77 million.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0005">AML.CS0005</a></td>
<td align="left"><a href="AML.CS0005">Attack on Machine Translation Service - Google Translate, Bing Translator, and Systran Translate</a></td>
<td align="left">Machine translation services (such as Google Translate, Bing Translator, and Systran Translate) provide public-facing UIs and APIs. A research group at UC Berkeley utilized these public endpoints to create a replicated model with near-production state-of-the-art translation quality. Beyond demonstrating that IP can be functionally stolen from a black-box system, they used the replicated model to successfully transfer adversarial examples to the real production services. These adversarial inputs successfully cause targeted word flips, vulgar outputs, and dropped sentences on Google Translate and Systran Translate websites.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0006">AML.CS0006</a></td>
<td align="left"><a href="AML.CS0006">ClearviewAI Misconfiguration</a></td>
<td align="left">Clearview AI makes a facial recognition tool that searches publicly available photos for matches.  This tool has been used for investigative purposes by law enforcement agencies and other parties.  Clearview AI's source code repository, though password protected, was misconfigured to allow an arbitrary user to register an account. This allowed an external researcher to gain access to a private code repository that contained Clearview AI production credentials, keys to cloud storage buckets containing 70K video samples, and copies of its applications and Slack tokens. With access to training data, a bad-actor has the ability to cause an arbitrary misclassification in the deployed model. These kinds of attacks illustrate that any attempt to secure ML system should be on top of "traditional" good cybersecurity hygiene such as locking down the system with least privileges, multi-factor authentication and monitoring and auditing.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0007">AML.CS0007</a></td>
<td align="left"><a href="AML.CS0007">GPT-2 Model Replication</a></td>
<td align="left">OpenAI built GPT-2, a language model capable of generating high quality text samples. Over concerns that GPT-2 could be used for malicious purposes such as impersonating others, or generating misleading news articles, fake social media content, or spam, OpenAI adopted a tiered release schedule. They initially released a smaller, less powerful version of GPT-2 along with a technical description of the approach, but held back the full trained model.  Before the full model was released by OpenAI, researchers at Brown University successfully replicated the model using information released by OpenAI and open source ML artifacts. This demonstrates that a bad actor with sufficient technical skill and compute resources could have replicated GPT-2 and used it for harmful goals before the AI Security community is prepared.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0008">AML.CS0008</a></td>
<td align="left"><a href="AML.CS0008">ProofPoint Evasion</a></td>
<td align="left">Proof Pudding (CVE-2019-20634) is a code repository that describes how ML researchers evaded ProofPoint's email protection system by first building a copy-cat email protection ML model, and using the insights to bypass the live system. More specifically, the insights allowed researchers to craft malicious emails that received preferable scores, going undetected by the system. Each word in an email is scored numerically based on multiple variables and if the overall score of the email is too low, ProofPoint will output an error, labeling it as SPAM.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0009">AML.CS0009</a></td>
<td align="left"><a href="AML.CS0009">Tay Poisoning</a></td>
<td align="left">Microsoft created Tay, a Twitter chatbot designed to engage and entertain users. While previous chatbots used pre-programmed scripts to respond to prompts, Tay's machine learning capabilities allowed it to be directly influenced by its conversations.  A coordinated attack encouraged malicious users to tweet abusive and offensive language at Tay, which eventually led to Tay generating similarly inflammatory content towards other users.  Microsoft decommissioned Tay within 24 hours of its launch and issued a public apology with lessons learned from the bot's failure.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0010">AML.CS0010</a></td>
<td align="left"><a href="AML.CS0010">Microsoft Azure Service Disruption</a></td>
<td align="left">The Microsoft AI Red Team performed a red team exercise on an internal Azure service with the intention of disrupting its service. This operation had a combination of traditional ATT&amp;CK enterprise techniques such as finding valid account, and exfiltrating data -- all interleaved with adversarial ML specific steps such as offline and online evasion examples.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0011">AML.CS0011</a></td>
<td align="left"><a href="AML.CS0011">Microsoft Edge AI Evasion</a></td>
<td align="left">The Azure Red Team performed a red team exercise on a new Microsoft product designed for running AI workloads at the Edge. This exercise was meant to use a automated system to continuously manipulate a target image to cause the ML model to produce misclassifications.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0012">AML.CS0012</a></td>
<td align="left"><a href="AML.CS0012">Face Identification System Evasion via Physical Countermeasures</a></td>
<td align="left">MITRE's AI Red Team demonstrated a physical-domain evasion attack on a commercial face identification service with the intention of inducing a targeted misclassification. This operation had a combination of traditional ATT&amp;CK enterprise techniques such as finding Valid account, and Executing code via an API - all interleaved with adversarial ML specific attacks.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0013">AML.CS0013</a></td>
<td align="left"><a href="AML.CS0013">Backdoor Attack on Deep Learning Models in Mobile Apps</a></td>
<td align="left">Deep learning models are increasingly used in mobile applications as critical components. Researchers from Microsoft Research demonstrated that many deep learning models deployed in mobile apps are vulnerable to backdoor attacks via "neural payload injection." They conducted an empirical study on real-world mobile deep learning apps collected from Google Play. They identified 54 apps that were vulnerable to attack, including popular security and safety critical applications used for cash recognition, parental control, face authentication, and financial services.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0014">AML.CS0014</a></td>
<td align="left"><a href="AML.CS0014">Confusing Antimalware Neural Networks</a></td>
<td align="left">Cloud storage and computations have become popular platforms for deploying ML malware detectors. In such cases, the features for models are built on users' systems and then sent to cybersecurity company servers. The Kaspersky ML research team explored this gray-box scenario and showed that feature knowledge is enough for an adversarial attack on ML models.  They attacked one of Kaspersky's antimalware ML models without white-box access to it and successfully evaded detection for most of the adversarially modified malware files.</td>
</tr>
<tr>
<td align="left"><a href="AML.CS0015">AML.CS0015</a></td>
<td align="left"><a href="AML.CS0015">Tesla Auto Wiper and Enhanced Autopilot Attack</a></td>
<td align="left">Tesla Auto Wipers and Enhanced Autopilot driving mode both make use of computer vision machine learning models to determine the vehicle's corresponding functions. These functions can be exploited by physical adversarial machine learning attacks that affect the operation and the safety of the vehicle. While exploits to gain root access to the Tesla firmware had since been patched, the vulnerabilities to the underlying machine learning systems discovered by this research were still exploitable.</td>
</tr>
</tbody>
</table>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../faq/" class="md-footer__link md-footer__link--prev" aria-label="Previous: FAQ" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              FAQ
            </div>
          </div>
        </a>
      
      
        
        <a href="AML.CS0000/" class="md-footer__link md-footer__link--next" aria-label="Next: Evasion of Deep Learning Detector for Malware C&amp;C Traffic" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Evasion of Deep Learning Detector for Malware C&C Traffic
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021-2022 The MITRE Corporation | v4.0.0
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.indexes"], "search": "../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.748e2769.min.js"></script>
      
    
  </body>
</html>